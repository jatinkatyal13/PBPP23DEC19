{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align:center;font-size:70px;background-color:#0ad61b;color:white;font-style:italic;\">Python for web</p>\n",
    "\n",
    "![](http://www.blog.skytopper.com/wp-content/uploads/2015/06/Global-computer-network.jpg)\n",
    "\n",
    "This bootcamp is all about interacting with **web** using Python programming language!\n",
    "\n",
    "In this bootcamp, we will learn:\n",
    "\n",
    "- to work with web APIs\n",
    "- to download content from web\n",
    "- web scraping\n",
    "- web automation\n",
    "\n",
    "using simple python scripts!\n",
    "\n",
    "![](https://i.amz.mshcdn.com/mqczOBQlR2uS7uALqB4fkKylDx0=/fit-in/1200x9600/https%3A%2F%2Fblueprint-api-production.s3.amazonaws.com%2Fuploads%2Fcard%2Fimage%2F193985%2Fnewhere.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Working with web APIs\n",
    "\n",
    "- **What is API?**<br>\n",
    "    API is a set of routines, protocols, and tools for building software applications. An API specifies how software components should interact. \n",
    "![](https://www.retriever.nl/wp-content/uploads/2016/11/api-321x250.png)\n",
    "-------------\n",
    "\n",
    "- **What is web API?**<br>\n",
    "    Web API is a framework for building HTTP services that can be consumed by a broad range of clients including browsers, mobiles, iphone and tablets.\n",
    "![](http://dselva.co.in/blog/wp-content/uploads/2017/09/Web-APIs.png)\n",
    "-----------------\n",
    "- **Some examples of public web APIs:**\n",
    "    - [Facebook Graph API](https://developers.facebook.com/docs/graph-api)\n",
    "    - [Twitter API](https://dev.twitter.com/rest/public)\n",
    "    - [Google API explorer](https://developers.google.com/apis-explorer/#p/)\n",
    "--------------\n",
    "\n",
    "- **What is REST?**<br>\n",
    "    REST is an architectural style followed by web services, in which, they allow requesting systems to access and manipulate their Web resources using a uniform and predefined set of **stateless operations**.\n",
    "    \n",
    "    >In computing, a stateless protocol is a communications protocol in which no information is retained by either sender or receiver. The sender transmits a packet to the receiver and does not expect an acknowledgment of receipt. There is nothing saved that has to be remembered by the next transaction. The server must be able to completely understand the client request without using any server context or server session state. \n",
    "    \n",
    "   Advantages of REST:\n",
    "   - As the transactions are stateless, we can direct them to any instance of the web service. (As no sessions are involved). Hence, the web service can scale to accommodate load changes.\n",
    "   - Binding to a service through an API is a matter of controlling how the URL is decoded.\n",
    "\n",
    "-----------------\n",
    "- **Types of HTTP requests**\n",
    "    - GET\n",
    "    - POST\n",
    "    - DELETE\n",
    "    - PUT\n",
    "    - PATCH, etc.\n",
    "    \n",
    "![](http://lotsofthing.com/wp-content/uploads/2017/11/rest-api-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP  for humans: [requests](http://docs.python-requests.org/en/master/)\n",
    "\n",
    "<img src=\"http://docs.python-requests.org/en/master/_static/requests-sidebar.png\"  height=200 width=200>\n",
    "\n",
    "\n",
    "- Requests is one of the most downloaded Python packages of all time, pulling in over 7,000,000 downloads every month.All the cool kids are doing it\n",
    "\n",
    "- Recreational use of other HTTP libraries may result in dangerous side-effects, including: security vulnerabilities, verbose code, reinventing the wheel, constantly reading documentation, depression, headaches, or even death. Requests is the only Non-GMO HTTP library for Python, safe for human consumption.\n",
    "\n",
    "- Python HTTP: When in doubt, or when not in doubt, use Requests. Beautiful, simple, Pythonic.\n",
    "\n",
    "***Everybody loves it!***\n",
    "\n",
    "#### Installation\n",
    "\n",
    "```\n",
    "pip install requests\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET request\n",
    "\n",
    "### Example 1\n",
    "\n",
    "http://graph.facebook.com/4/picture?type=large\n",
    "\n",
    "![](http://graph.facebook.com/4/picture?type=large)\n",
    "\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTJ3ELNuC_coeH9tvLn62fsTMoe-vMVQrsfTrLUOIhsUI69i5QIyg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://graph.facebook.com/4/picture?type=large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Last-Modified': 'Mon, 16 Dec 2019 00:16:08 GMT', 'Accept-Ranges': 'bytes', 'x-haystack-needlechecksum': '2760348236', 'x-needle-checksum': '568539172', 'Content-Type': 'image/jpeg', 'x-fb-config-version-olb-prod': '664', 'timing-allow-origin': '*', 'Access-Control-Allow-Origin': '*', 'Cache-Control': 'max-age=1209600, no-transform', 'X-FB-TRIP-ID': '850421930', 'Date': 'Thu, 02 Jan 2020 11:39:32 GMT', 'Alt-Svc': 'h3-24=\":443\"; ma=3600', 'Access-Control-Expose-Headers': 'X-FB-CEC-Video-Limit', 'Connection': 'keep-alive', 'Content-Length': '8173'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image/jpeg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers['Content-Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mark.jpeg\", \"wb\") as file:\n",
    "    file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pictures/1.png'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"pictures/{}.{}\".format(1, \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://graph.facebook.com/{}/picture?type=large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://graph.facebook.com/4/picture?type=large'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url.format(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 4\n",
      "done 5\n",
      "done 6\n",
      "done 7\n",
      "done 8\n",
      "done 9\n",
      "done 10\n",
      "done 11\n",
      "done 12\n",
      "done 13\n",
      "done 14\n",
      "done 15\n",
      "done 16\n",
      "done 17\n",
      "done 18\n",
      "done 19\n",
      "done 20\n",
      "done 21\n",
      "done 22\n",
      "done 23\n",
      "done 24\n",
      "done 25\n",
      "done 26\n",
      "done 27\n",
      "done 28\n",
      "done 29\n",
      "done 30\n",
      "done 31\n",
      "done 32\n",
      "done 33\n",
      "done 34\n",
      "done 35\n",
      "done 36\n",
      "done 37\n",
      "done 38\n",
      "done 39\n",
      "done 40\n",
      "done 41\n",
      "done 42\n",
      "done 43\n",
      "done 44\n",
      "done 45\n",
      "done 46\n",
      "done 47\n",
      "done 48\n",
      "done 49\n",
      "done 50\n",
      "done 51\n",
      "done 52\n",
      "done 53\n",
      "done 54\n",
      "done 55\n",
      "done 56\n",
      "done 57\n",
      "done 58\n",
      "done 59\n",
      "done 60\n",
      "done 61\n",
      "done 62\n",
      "done 63\n",
      "done 64\n",
      "done 65\n",
      "done 66\n",
      "done 67\n",
      "done 68\n",
      "done 69\n",
      "done 70\n",
      "done 71\n",
      "done 72\n",
      "done 73\n",
      "done 74\n",
      "done 75\n",
      "done 76\n",
      "done 77\n",
      "done 78\n",
      "done 79\n",
      "done 80\n",
      "done 81\n",
      "done 82\n",
      "done 83\n",
      "done 84\n",
      "done 85\n",
      "done 86\n",
      "done 87\n",
      "done 88\n",
      "done 89\n",
      "done 90\n",
      "done 91\n",
      "done 92\n",
      "done 93\n",
      "done 94\n",
      "done 95\n",
      "done 96\n",
      "done 97\n",
      "done 98\n",
      "done 99\n",
      "done 100\n",
      "done 101\n",
      "done 102\n",
      "done 103\n",
      "done 104\n",
      "done 105\n",
      "done 106\n",
      "done 107\n",
      "done 108\n",
      "done 109\n",
      "done 110\n",
      "done 111\n",
      "done 112\n",
      "done 113\n",
      "done 114\n",
      "done 115\n",
      "done 116\n",
      "done 117\n",
      "done 118\n",
      "done 119\n",
      "done 120\n",
      "done 121\n",
      "done 122\n",
      "done 123\n",
      "done 124\n",
      "done 125\n",
      "done 126\n",
      "done 127\n",
      "done 128\n",
      "done 129\n",
      "done 130\n",
      "done 131\n",
      "done 132\n",
      "done 133\n",
      "done 134\n",
      "done 135\n",
      "done 136\n",
      "done 137\n",
      "done 138\n",
      "done 139\n",
      "done 140\n",
      "done 141\n",
      "done 142\n",
      "done 143\n",
      "done 144\n",
      "done 145\n",
      "done 146\n",
      "done 147\n",
      "done 148\n",
      "done 149\n",
      "done 150\n",
      "done 151\n",
      "done 152\n",
      "done 153\n",
      "done 154\n",
      "done 155\n",
      "done 156\n",
      "done 157\n",
      "done 158\n",
      "done 159\n",
      "done 160\n",
      "done 161\n",
      "done 162\n",
      "done 163\n",
      "done 164\n",
      "done 165\n",
      "done 166\n",
      "done 167\n",
      "done 168\n",
      "done 169\n",
      "done 170\n",
      "done 171\n",
      "done 172\n",
      "done 173\n",
      "done 174\n",
      "done 175\n",
      "done 176\n",
      "done 177\n",
      "done 178\n",
      "done 179\n",
      "done 180\n",
      "done 181\n",
      "done 182\n",
      "done 183\n",
      "done 184\n",
      "done 185\n",
      "done 186\n",
      "done 187\n",
      "done 188\n",
      "done 189\n",
      "done 190\n",
      "done 191\n",
      "done 192\n",
      "done 193\n",
      "done 194\n",
      "done 195\n",
      "done 196\n",
      "done 197\n",
      "done 198\n",
      "done 199\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 200):\n",
    "    r = requests.get(url.format(i))\n",
    "    with open(\"pictures/{}.jpg\".format(i), \"wb\") as file:\n",
    "        file.write(r.content)\n",
    "    \n",
    "    print(\"done\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i.imgur.com/gRvt4lV.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "[Google maps geocoding API](https://developers.google.com/maps/documentation/geocoding/intro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST request\n",
    "\n",
    "![](https://indianpythonista.files.wordpress.com/2016/12/iservice_post_get.png?w=809)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "[Pastebin API](https://pastebin.com/api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Downloading files\n",
    "\n",
    "![](https://pics.onsizzle.com/downloading-98-downloading-99-downloading-failed-11367153.png)\n",
    "\n",
    "Downloading large files in chunks!\n",
    "\n",
    "http://www.greenteapress.com/thinkpython/thinkpython.pdf\n",
    "\n",
    "```python\n",
    "chunk_size = 256\n",
    "r = requests.get(url, stream=True)\n",
    "\n",
    "with open(\"python.pdf\", \"wb\") as f:\n",
    "    for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "        f.write(chunk)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.hq.nasa.gov/alsj/a17/A17_FlightPlan.pdf\"\n",
    "r = requests.get(url, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Thu, 02 Jan 2020 12:15:06 GMT', 'Server': 'Apache', 'Strict-Transport-Security': 'max-age=63072000; includeSubdomains; preload', 'X-Content-Type-Options': 'nosniff', 'X-Frame-Options': 'SAMEORIGIN', 'Last-Modified': 'Sun, 19 May 2002 14:49:00 GMT', 'Accept-Ranges': 'bytes', 'Content-Length': '20702285', 'Keep-Alive': 'timeout=15, max=100', 'Connection': 'Keep-Alive', 'Content-Type': 'application/pdf'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.iter_content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1024\n",
    "with open(\"file.pdf\", \"wb\") as file:\n",
    "    for chunk in r.iter_content(chunk_size):\n",
    "        file.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm(range(10), total = 10):\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20218/20218 [00:20<00:00, 972.25it/s] \n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.hq.nasa.gov/alsj/a17/A17_FlightPlan.pdf\"\n",
    "r = requests.get(url, stream=True)\n",
    "\n",
    "file_size = int(r.headers['content-length'])\n",
    "chunk_size = 1024\n",
    "no_of_iterations = math.ceil(file_size / chunk_size)\n",
    "\n",
    "with open(\"file.pdf\", \"wb\") as file:\n",
    "    for chunk in tqdm(r.iter_content(chunk_size), total = no_of_iterations):\n",
    "        file.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Web scraping\n",
    "\n",
    "![](https://image.slidesharecdn.com/scrapingtotherescue-160713133749/95/getting-started-with-web-scraping-in-python-9-638.jpg?cb=1468417631)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "\n",
    ">Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.\n",
    "\n",
    "### Installation\n",
    "\n",
    "```\n",
    "pip install bs4\n",
    "```\n",
    "\n",
    "**Bonus:**\n",
    "```\n",
    "pip install html5lib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.values.com/inspirational-quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.entropywebscraping.com/wp-content/uploads/2017/02/Screenshot-from-2017-02-01-10-23-00.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Web automation\n",
    " \n",
    " ![](https://images.contentful.com/qs7jgwzogkzr/6HeUbprAsMYek2Keqi0WYo/d8ad7cf2f15e706ead76e00a53859cc7/testing-automation-alternatives.jpg)\n",
    " \n",
    " **Task:** Automatically submit the code for a [problem](https://www.codechef.com/problems/TEST) on [codechef](https://www.codechef.com/).\n",
    " \n",
    " ### [Selenium](http://selenium-python.readthedocs.io/) : Web automation and testing\n",
    " \n",
    " ![](https://udemy-images.udemy.com/course/750x422/482754_7146_4.jpg)\n",
    " \n",
    " \n",
    " #### Installation\n",
    " \n",
    " - To install python bindings for selenium:\n",
    "     ```\n",
    "     pip install selenium\n",
    "     ```\n",
    "     \n",
    " - To install webdriver:\n",
    " \n",
    "     http://selenium-python.readthedocs.io/installation.html#drivers\n",
    "     \n",
    "     [How to put webdriver in PATH?](https://stackoverflow.com/questions/40208051/selenium-using-python-geckodriver-executable-needs-to-be-in-path)\n",
    " \n",
    " #### To start a browser session\n",
    " ```python\n",
    " from selenium import webdriver\n",
    " browser = webdriver.Chrome()\n",
    " ```\n",
    " \n",
    " #### To open a webpage\n",
    " ```python\n",
    " browser.get('https://www.codechef.com')\n",
    " ```\n",
    " \n",
    " #### To select an element by its id\n",
    " ```python\n",
    " browser.find_element_by_id(<id>)\n",
    " ```\n",
    " \n",
    " #### Input value in element\n",
    " ```python\n",
    " element.send_keys()\n",
    " ```\n",
    " \n",
    " #### Click on an element\n",
    " ```python\n",
    " element.click()\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgflip.com/poxkz.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resourses:\n",
    "\n",
    "- Python packages:\n",
    "\n",
    "    - [requests](http://docs.python-requests.org/en/master/)\n",
    "\n",
    "    - [bs4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "    \n",
    "    - [html5lib](https://html5lib.readthedocs.io/en/latest/)\n",
    " \n",
    "\n",
    "- Articles:\n",
    "\n",
    "    - https://indianpythonista.wordpress.com/2016/12/10/get-and-post-requests-using-python/\n",
    "\n",
    "    - https://indianpythonista.wordpress.com/2016/10/18/requests-http-for-pythonistas/\n",
    "\n",
    "    - https://indianpythonista.wordpress.com/2016/12/10/downloading-files-from-web-using-python/\n",
    "\n",
    "    - https://indianpythonista.wordpress.com/2016/12/10/implementing-web-scraping-in-python-with-beautiful-soup/\n",
    "\n",
    "\n",
    "- Videos:\n",
    "\n",
    "    - File downloader: https://www.youtube.com/watch?v=Xhw2l-hzoKk\n",
    "    - Web scraping: https://www.youtube.com/watch?v=lIkd_jt28i0&t=557s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
